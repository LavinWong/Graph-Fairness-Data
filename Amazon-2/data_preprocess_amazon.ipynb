{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read user, item and rating from the raw files\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "VideoGame_df = pd.read_csv('./ratings_Video_Games.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "VideoGame_df['genre'] = 'VideoGame'\n",
    "\n",
    "Toy_df = pd.read_csv('./ratings_Toys_and_Games.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Toy_df['genre'] = 'Toy'\n",
    "\n",
    "Tool_df = pd.read_csv('./ratings_Tools_and_Home_Improvement.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Tool_df['genre'] = 'Tool'\n",
    "\n",
    "Pet_df = pd.read_csv('./ratings_Pet_Supplies.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Pet_df['genre'] = 'Pet'\n",
    "\n",
    "Office_df = pd.read_csv('./ratings_Office_Products.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Office_df['genre'] = 'Office'\n",
    "\n",
    "Beauty_df = pd.read_csv('./ratings_Beauty.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Beauty_df['genre'] = 'Beauty'\n",
    "\n",
    "Grocery_df = pd.read_csv('./ratings_Grocery_and_Gourmet_Food.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Grocery_df['genre'] = 'Grocery'\n",
    "\n",
    "rdf = pd.concat([Office_df, Grocery_df, Toy_df, Pet_df, Tool_df, Beauty_df, VideoGame_df], sort=False)\n",
    "rdf.drop(columns=['time'], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 1287010\n",
      "user num = 5224928\n"
     ]
    }
   ],
   "source": [
    "rdf.reset_index(drop=True, inplace=True)\n",
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A3V6Z4RCDGRC44    507\n",
       "AEL6CQNQXONBX     392\n",
       "ALNFHVS3SC4FV     389\n",
       "A3OXHLG6DIBRW8    380\n",
       "A1UQBFCERIP7VJ    364\n",
       "A3W4D8XOGLWUN5    362\n",
       "A22CW0ZHY3NJH8    345\n",
       "AJKWF4W7QD4NS     339\n",
       "A3NHUQ33CFH3VM    332\n",
       "AAA0TUKS5VBSA     316\n",
       "A1ODOGXEYECQQ8    315\n",
       "ACJT8MUC0LRF0     314\n",
       "A2QHS1ZCIQOL7E    304\n",
       "A1ITRGMT80D5TK    300\n",
       "A29BQ6B90Y1R5F    299\n",
       "A1F7YU6O5RU432    297\n",
       "A25C2M3QF9G7OQ    296\n",
       "A2QDOJFFLFGF18    292\n",
       "A1EVV74UQYVKRY    290\n",
       "A2OCDK0BOW6UCY    280\n",
       "A2P739KOM4U5JB    280\n",
       "A2R1HUYHXV7H18    279\n",
       "A2YKWYC3WQJX5J    273\n",
       "A34BZM6S9L7QI4    261\n",
       "A1W415JP5WEAJK    258\n",
       "AFV2584U13XP3     257\n",
       "AKMEY1BSHSDG7     255\n",
       "A376OJHLE6SU9Q    253\n",
       "A3R5GTYQ50QVMD    252\n",
       "A36MP37DITBU6F    252\n",
       "                 ... \n",
       "AYRQRVL0ZFK5X      10\n",
       "A2GX3844AHLQ72     10\n",
       "A34WVVGTD4RI4V     10\n",
       "A31304ZQ73RM1D     10\n",
       "ADUSJHGS14HX7      10\n",
       "A166ZEAUD9303A     10\n",
       "A1L1HD37BLH2TS     10\n",
       "A1JYBIA81NZ282     10\n",
       "A2BWZGD7S0JZQJ     10\n",
       "A1GWCZR5ZTRM6Z     10\n",
       "A3OT5V13SCOODS     10\n",
       "ACQF3DSBMIYI1      10\n",
       "A2V9VS4VWCSCNK     10\n",
       "A1W9C4TZA5YCBL     10\n",
       "A3PPYV0LUBM14W     10\n",
       "A3IYAP6830Y9TI     10\n",
       "A30IW59HCR7WUQ     10\n",
       "A3TGW4JU3KTG52     10\n",
       "A2ET7GKH3FCY4F     10\n",
       "A2NN2T8Z97SZ8I     10\n",
       "A2RCM2B4NQDII0     10\n",
       "A2P8YANRF6R0YM     10\n",
       "A2NU9H8H5MJZSL     10\n",
       "A2G4A7LS78GTXF     10\n",
       "A15T487HNTIOF7     10\n",
       "AN9EWQN1LGMY7      10\n",
       "A2086ZWT3NFBWL     10\n",
       "ARRKEMHZJY9VB      10\n",
       "A17UEV3W4G7WJL     10\n",
       "A1OC3U7Y1AGFXB     10\n",
       "Name: user_id, Length: 17083, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteratively remove items and users with less than 10 reviews\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['user_freq'] <= 9], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "rdf['item_freq'] = rdf.groupby('item_id')['item_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['item_freq'] <= 9], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 13582\n",
      "user num = 17083\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VideoGame', 3126),\n",
       " ('Beauty', 1983),\n",
       " ('Toy', 1849),\n",
       " ('Grocery', 1843),\n",
       " ('Pet', 1711),\n",
       " ('Tool', 1575),\n",
       " ('Office', 1546)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "item_genre_dict = dict()\n",
    "for i in range(len(rdf)):\n",
    "    item = rdf.at[i, 'item_id']\n",
    "    genre = rdf.at[i, 'genre']\n",
    "    if item not in item_genre_dict:\n",
    "        item_genre_dict[item] = set([genre])\n",
    "    else:\n",
    "        if genre not in item_genre_dict[item]:\n",
    "            item_genre_dict[item].add(genre)\n",
    "\n",
    "import operator\n",
    "genre_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_count:\n",
    "            genre_count[g] = 1\n",
    "        else:\n",
    "            genre_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_genre = ['Office', 'Grocery', 'Tool', 'Pet', 'VideoGame', 'Toy', 'Beauty']\n",
    "\n",
    "# get the key_genre->item_list dict\n",
    "key_genre_item = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_item[k] = list()\n",
    "for item in item_genre_dict:\n",
    "    for g in item_genre_dict[item]:\n",
    "        if g in key_genre:\n",
    "            key_genre_item[g].append(item)\n",
    "            \n",
    "# collect all the items with key genres\n",
    "key_item = list()\n",
    "for genre in key_genre_item:\n",
    "    key_item = key_item + key_genre_item[genre]\n",
    "key_item_set = set(key_item)\n",
    "\n",
    "# remove the non-key genre items in rdf\n",
    "item_set = set(item_list)\n",
    "nonkey_item_set = item_set - key_item_set\n",
    "for item in nonkey_item_set:\n",
    "    rdf.drop(rdf.index[rdf['item_id'] == item], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user and item str id->int id dict\n",
    "i = 0\n",
    "user_id_dict = dict()\n",
    "for u in user_list:\n",
    "    if not u in user_id_dict:\n",
    "        user_id_dict[u] = i\n",
    "        i += 1\n",
    "j = 0\n",
    "item_id_dict = dict()\n",
    "for i in item_list:\n",
    "    if not i in item_id_dict:\n",
    "        item_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0017706951447\n"
     ]
    }
   ],
   "source": [
    "print('sparsity: ' + str(len(rdf) * 1.0 / (len(user_list) * len(item_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/17083\n",
      "10000/17083\n",
      "15000/17083\n"
     ]
    }
   ],
   "source": [
    "# get the df of train, vali, and test set\n",
    "rdf.reset_index(inplace=True, drop=True)\n",
    "train_df = rdf.copy()\n",
    "vali_df = rdf.copy()\n",
    "test_df = rdf.copy()\n",
    "\n",
    "train_ratio = 0.6\n",
    "vali_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_all = len(rdf)\n",
    "vali_idx = []\n",
    "test_idx = []\n",
    "\n",
    "test_vali_idx = []\n",
    "i = 0\n",
    "num_user = len(user_list)\n",
    "for u in user_list:\n",
    "    u_idx = train_df.index[train_df['user_id'] == u]\n",
    "    idx_len = len(u_idx)\n",
    "    test_len = int(idx_len * (test_ratio + vali_ratio))\n",
    "    if test_len == 0:\n",
    "        test_len = 1\n",
    "    tmp = np.random.choice(u_idx, size=test_len, replace=False)\n",
    "    test_vali_idx += tmp.tolist()\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print(str(i) + '/' + str(num_user))\n",
    "\n",
    "# tmp = (np.random.choice(range(num_all), size=(test_len+vali_len), replace=False)).tolist()\n",
    "test_len = int(len(test_vali_idx) * test_ratio / (test_ratio + vali_ratio))\n",
    "vali_len = int(len(test_vali_idx) - test_len)\n",
    "test_idx = (np.random.choice(test_vali_idx, size=test_len, replace=False)).tolist()\n",
    "vali_idx = (np.random.choice(test_vali_idx, size=vali_len, replace=False)).tolist()\n",
    "\n",
    "test_set = set(test_idx)\n",
    "vali_set = set(vali_idx)\n",
    "train_set = set(range(num_all)) - test_set - vali_set\n",
    "train_idx = list(train_set)\n",
    "train_df.drop((test_idx + vali_idx), axis=0, inplace=True)\n",
    "test_df.drop((train_idx + vali_idx), axis=0, inplace=True)\n",
    "vali_df.drop((train_idx + test_idx), axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.drop(columns=['rating'], inplace=True)\n",
    "train_df.drop(columns=['rating'], inplace=True)\n",
    "test_df.drop(columns=['rating'], inplace=True)\n",
    "vali_df.drop(columns=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix of train, vali and test set\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "train = np.zeros((len(user_list), len(item_list)))\n",
    "test = np.zeros((len(user_list), len(item_list)))\n",
    "vali = np.zeros((len(user_list), len(item_list)))\n",
    "for r in range(len(train_df)):\n",
    "    train[user_id_dict[train_df.at[r, 'user_id']], item_id_dict[train_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(test_df)):\n",
    "    test[user_id_dict[test_df.at[r, 'user_id']], item_id_dict[test_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(vali_df)):\n",
    "    vali[user_id_dict[vali_df.at[r, 'user_id']], item_id_dict[vali_df.at[r, 'item_id']]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user int id-> str id list, and the same for item \n",
    "item_list = item_id_dict.keys()\n",
    "item_idd_list = list()\n",
    "for i in range(len(item_list)):\n",
    "    item_idd_list.append('')\n",
    "for item in item_id_dict:\n",
    "    item_idd_list[item_id_dict[item]] = item\n",
    "\n",
    "user_list = user_id_dict.keys()\n",
    "user_idd_list = list()\n",
    "for i in range(len(user_list)):\n",
    "    user_idd_list.append('')\n",
    "for user in user_id_dict:\n",
    "    user_idd_list[user_id_dict[user]] = user\n",
    "    \n",
    "# get the item int id->genres list\n",
    "item_idd_genre_list = list()\n",
    "for i in range(len(item_idd_list)):\n",
    "    item_idd_genre_list.append(item_genre_dict[item_idd_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('user_freq', axis=1, inplace=True)\n",
    "train_df.drop('item_freq', axis=1, inplace=True)\n",
    "vali_df.drop('user_freq', axis=1, inplace=True)\n",
    "vali_df.drop('item_freq', axis=1, inplace=True)\n",
    "test_df.drop('user_freq', axis=1, inplace=True)\n",
    "test_df.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df for rdf, train, vali, test with int id for user and item\n",
    "import copy\n",
    "rating_df = copy.copy(rdf)\n",
    "for i in range(len(rdf)):\n",
    "    rating_df.at[i, 'user_id'] = user_id_dict[rating_df.at[i, 'user_id']]\n",
    "    rating_df.at[i, 'item_id'] = item_id_dict[rating_df.at[i, 'item_id']]\n",
    "\n",
    "training_df = copy.copy(train_df)\n",
    "for i in range(len(training_df)):\n",
    "    training_df.at[i, 'user_id'] = user_id_dict[training_df.at[i, 'user_id']]\n",
    "    training_df.at[i, 'item_id'] = item_id_dict[training_df.at[i, 'item_id']]\n",
    "\n",
    "valiing_df = copy.copy(vali_df)\n",
    "for i in range(len(valiing_df)):\n",
    "    valiing_df.at[i, 'user_id'] = user_id_dict[valiing_df.at[i, 'user_id']]\n",
    "    valiing_df.at[i, 'item_id'] = item_id_dict[valiing_df.at[i, 'item_id']]\n",
    "\n",
    "testing_df = copy.copy(test_df)\n",
    "for i in range(len(testing_df)):\n",
    "    testing_df.at[i, 'user_id'] = user_id_dict[testing_df.at[i, 'user_id']]\n",
    "    testing_df.at[i, 'item_id'] = item_id_dict[testing_df.at[i, 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the rating list for each key genre, get the genre->ratings dict\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "key_genre_rating = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_rating[k] = 0.0\n",
    "for r in range(len(rdf)):\n",
    "    item = rdf.at[r, 'item_id']\n",
    "    gl = item_genre_dict[item]\n",
    "    for k in key_genre:\n",
    "        if k in gl:\n",
    "            key_genre_rating[k] += 1.0\n",
    "\n",
    "# get the item int id->genres list\n",
    "genre_item_vector = dict()\n",
    "for k in key_genre:\n",
    "    genre_item_vector[k] = np.zeros((1, len(item_list)))\n",
    "for i in range(len(item_idd_genre_list)):\n",
    "    genre_list = item_idd_genre_list[i]\n",
    "    for g in genre_list:\n",
    "        if g in key_genre:\n",
    "            genre_item_vector[g][0, i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"item_genre_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_genre_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"genre_item_vector.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_item_vector, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rdf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rdf, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rating_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rating_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"training_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"valiing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(valiing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"testing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(testing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_genre_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_genre_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre_rating.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre_rating, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"train.mat\", \"wb\") as f:\n",
    "    np.save(f, train)\n",
    "with open(\"test.mat\", \"wb\") as f:\n",
    "    np.save(f, test)\n",
    "with open(\"vali.mat\", \"wb\") as f:\n",
    "    np.save(f, vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VideoGame', 3126),\n",
       " ('Beauty', 1983),\n",
       " ('Toy', 1849),\n",
       " ('Grocery', 1843),\n",
       " ('Pet', 1711),\n",
       " ('Tool', 1575),\n",
       " ('Office', 1546)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "# item_list = pickle.load(open('./rdf.pkl'))['item_id'].unique()\n",
    "# item_genre_dict = pickle.load(open('./item_genre_dict.pkl'))\n",
    "# key_genre = pickle.load(open('./key_genre.pkl'))\n",
    "\n",
    "genre_count = dict()\n",
    "for i in item_list:\n",
    "    gl = item_genre_dict[i]\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            if not g in genre_count:\n",
    "                genre_count[g] = 1\n",
    "            else:\n",
    "                genre_count[g] += 1\n",
    "\n",
    "with open(\"genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_count, f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "genre_count_sorted = sorted(genre_count.items(), key=itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy as copy\n",
    "\n",
    "item_idd_genre_list = np.array(item_idd_genre_list)\n",
    "\n",
    "\n",
    "mask = 1.0 * (train > 0)\n",
    "user_genre_count = list()\n",
    "for u in range(train.shape[0]):\n",
    "    temp_genre_count = copy.copy(genre_count)\n",
    "    mask_u = mask[u, :]\n",
    "    gll = item_idd_genre_list[mask_u == 1.0]\n",
    "    for gl in gll:\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                temp_genre_count[g] -= 1\n",
    "    user_genre_count.append(temp_genre_count)\n",
    "with open(\"user_genre_count.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_genre_count, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_avg_like = dict()\n",
    "for k in key_genre:\n",
    "    genre_avg_like[k] = key_genre_rating[k] * 1.0 / genre_count[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Grocery', 41.76559956592512),\n",
       " ('Office', 35.058861578266495),\n",
       " ('Beauty', 32.53202218860313),\n",
       " ('Pet', 28.531852717708944),\n",
       " ('VideoGame', 27.901791426743443),\n",
       " ('Toy', 25.78583017847485),\n",
       " ('Tool', 22.16761904761905)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_avg_like_sorted = sorted(genre_avg_like.items(), key=itemgetter(1), reverse=True)\n",
    "genre_avg_like_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
