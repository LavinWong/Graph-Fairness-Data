{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read user, item and rating from the raw files\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# VideoGame_df = pd.read_csv('./ratings_Video_Games.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# VideoGame_df['genre'] = 'VideoGame'\n",
    "\n",
    "Toy_df = pd.read_csv('./ratings_Toys_and_Games.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Toy_df['genre'] = 'Toy'\n",
    "\n",
    "# Tool_df = pd.read_csv('./ratings_Tools_and_Home_Improvement.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# Tool_df['genre'] = 'Tool'\n",
    "\n",
    "# Pet_df = pd.read_csv('./ratings_Pet_Supplies.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# Pet_df['genre'] = 'Pet'\n",
    "\n",
    "# Office_df = pd.read_csv('./ratings_Office_Products.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# Office_df['genre'] = 'Office'\n",
    "\n",
    "# Beauty_df = pd.read_csv('./ratings_Beauty.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "# Beauty_df['genre'] = 'Beauty'\n",
    "\n",
    "Grocery_df = pd.read_csv('./ratings_Grocery_and_Gourmet_Food.csv', names=['user_id', 'item_id', 'rating', 'time'])\n",
    "Grocery_df['genre'] = 'Grocery'\n",
    "\n",
    "rdf = pd.concat([Grocery_df, Toy_df], sort=False)\n",
    "rdf.drop(columns=['time'], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 493746\n",
      "user num = 1974933\n"
     ]
    }
   ],
   "source": [
    "rdf.reset_index(drop=True, inplace=True)\n",
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1UQBFCERIP7VJ    167\n",
       "A2QDOJFFLFGF18    163\n",
       "AAA0TUKS5VBSA     160\n",
       "ACJT8MUC0LRF0     157\n",
       "A3OXHLG6DIBRW8    152\n",
       "ALNFHVS3SC4FV     146\n",
       "A1ITRGMT80D5TK    143\n",
       "A36MP37DITBU6F    125\n",
       "A1W415JP5WEAJK    122\n",
       "AEL6CQNQXONBX     118\n",
       "A3VI2VETB90ZG5    115\n",
       "ALQ4USPEQ9L5N     111\n",
       "A2V92F5R7MLCVI    108\n",
       "A16Z2OECAUX8Z4    108\n",
       "A3NHUQ33CFH3VM    107\n",
       "AGEKVD8JPZQMT     106\n",
       "A2RX62V4E2BF5Z    106\n",
       "AY3D7DG5L5WCK     106\n",
       "AKMEY1BSHSDG7     104\n",
       "A25C2M3QF9G7OQ    104\n",
       "A2P739KOM4U5JB    104\n",
       "A231LBC8EGPO5L    104\n",
       "A353U0L2HAMSHV    103\n",
       "A1II2ZRPKZAQQD    101\n",
       "A1Z54EM24Y40LL    101\n",
       "ALDAF4VVLFRHP      99\n",
       "A24RCBRDXRXR0Y     99\n",
       "A2OCDK0BOW6UCY     99\n",
       "AYB4ELCS5AM8P      98\n",
       "A22CW0ZHY3NJH8     97\n",
       "                 ... \n",
       "A20G8KX4NPD2SF      8\n",
       "A3JJNGCMI5DJGO      8\n",
       "A35V8JJBYADQB9      8\n",
       "A30ARMF3JEKEJY      8\n",
       "A1P5QZJB3QWL0B      8\n",
       "AJS7THAS9CZ59       8\n",
       "A3KJ6JAZPH382D      8\n",
       "AAIU4V0FTRZ2N       8\n",
       "AL0MLF4AINGY3       8\n",
       "ABKNRVFFLEA3M       8\n",
       "A19IDPU990VUBB      8\n",
       "A1WT3WVA0IJ5OO      8\n",
       "A1OQJ1C1NQOABK      8\n",
       "A8QITLROF01FW       8\n",
       "A17CQORLF0JIFL      8\n",
       "A3EEQO8MUXFINX      8\n",
       "A20F47COALTMJI      8\n",
       "A30R8VFR16RE32      8\n",
       "A10FJGRMOTJ35Y      8\n",
       "A1VT804QG340FV      8\n",
       "AAEVGE52KL0DJ       8\n",
       "A1HCCA1A6MUQVE      8\n",
       "A22PKZZK5DSONS      8\n",
       "A2BAAKZHSUGCDP      8\n",
       "ANPHYZGDANR45       8\n",
       "A8757LV5QW9VX       8\n",
       "A2IMH6HYO4AMFT      8\n",
       "A3VSUYCR2WFHI       8\n",
       "A1B990PTK39WT4      8\n",
       "A22BGI38W7Q9X9      8\n",
       "Name: user_id, Length: 3845, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteratively remove items and users with less than 10 reviews\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['user_freq'] <= 7], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "rdf['item_freq'] = rdf.groupby('item_id')['item_id'].transform('count')\n",
    "rdf.drop(rdf.index[rdf['item_freq'] <= 7], inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "rdf['user_freq'] = rdf.groupby('user_id')['user_id'].transform('count')\n",
    "rdf['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item num = 2487\n",
      "user num = 3845\n"
     ]
    }
   ],
   "source": [
    "item_list = rdf['item_id'].unique()\n",
    "user_list = rdf['user_id'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Toy', 1307), ('Grocery', 1180)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "item_genre_dict = dict()\n",
    "for i in range(len(rdf)):\n",
    "    item = rdf.at[i, 'item_id']\n",
    "    genre = rdf.at[i, 'genre']\n",
    "    if item not in item_genre_dict:\n",
    "        item_genre_dict[item] = set([genre])\n",
    "    else:\n",
    "        if genre not in item_genre_dict[item]:\n",
    "            item_genre_dict[item].add(genre)\n",
    "\n",
    "import operator\n",
    "genre_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_count:\n",
    "            genre_count[g] = 1\n",
    "        else:\n",
    "            genre_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_genre = ['Grocery', 'Toy']\n",
    "\n",
    "# get the key_genre->item_list dict\n",
    "key_genre_item = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_item[k] = list()\n",
    "for item in item_genre_dict:\n",
    "    for g in item_genre_dict[item]:\n",
    "        if g in key_genre:\n",
    "            key_genre_item[g].append(item)\n",
    "            \n",
    "# collect all the items with key genres\n",
    "key_item = list()\n",
    "for genre in key_genre_item:\n",
    "    key_item = key_item + key_genre_item[genre]\n",
    "key_item_set = set(key_item)\n",
    "\n",
    "# remove the non-key genre items in rdf\n",
    "item_set = set(item_list)\n",
    "nonkey_item_set = item_set - key_item_set\n",
    "for item in nonkey_item_set:\n",
    "    rdf.drop(rdf.index[rdf['item_id'] == item], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user and item str id->int id dict\n",
    "i = 0\n",
    "user_id_dict = dict()\n",
    "for u in user_list:\n",
    "    if not u in user_id_dict:\n",
    "        user_id_dict[u] = i\n",
    "        i += 1\n",
    "j = 0\n",
    "item_id_dict = dict()\n",
    "for i in item_list:\n",
    "    if not i in item_id_dict:\n",
    "        item_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.00885290114578\n"
     ]
    }
   ],
   "source": [
    "print('sparsity: ' + str(len(rdf) * 1.0 / (len(user_list) * len(item_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the df of train, vali, and test set\n",
    "rdf.reset_index(inplace=True, drop=True)\n",
    "train_df = rdf.copy()\n",
    "vali_df = rdf.copy()\n",
    "test_df = rdf.copy()\n",
    "\n",
    "train_ratio = 0.6\n",
    "vali_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "num_all = len(rdf)\n",
    "vali_idx = []\n",
    "test_idx = []\n",
    "\n",
    "test_vali_idx = []\n",
    "i = 0\n",
    "num_user = len(user_list)\n",
    "for u in user_list:\n",
    "    u_idx = train_df.index[train_df['user_id'] == u]\n",
    "    idx_len = len(u_idx)\n",
    "    test_len = int(idx_len * (test_ratio + vali_ratio))\n",
    "    if test_len == 0:\n",
    "        test_len = 1\n",
    "    tmp = np.random.choice(u_idx, size=test_len, replace=False)\n",
    "    test_vali_idx += tmp.tolist()\n",
    "    i += 1\n",
    "    if i % 5000 == 0:\n",
    "        print(str(i) + '/' + str(num_user))\n",
    "\n",
    "# tmp = (np.random.choice(range(num_all), size=(test_len+vali_len), replace=False)).tolist()\n",
    "test_len = int(len(test_vali_idx) * test_ratio / (test_ratio + vali_ratio))\n",
    "vali_len = int(len(test_vali_idx) - test_len)\n",
    "test_idx = (np.random.choice(test_vali_idx, size=test_len, replace=False)).tolist()\n",
    "vali_idx = (np.random.choice(test_vali_idx, size=vali_len, replace=False)).tolist()\n",
    "\n",
    "test_set = set(test_idx)\n",
    "vali_set = set(vali_idx)\n",
    "train_set = set(range(num_all)) - test_set - vali_set\n",
    "train_idx = list(train_set)\n",
    "train_df.drop((test_idx + vali_idx), axis=0, inplace=True)\n",
    "test_df.drop((train_idx + vali_idx), axis=0, inplace=True)\n",
    "vali_df.drop((train_idx + test_idx), axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.drop(columns=['rating'], inplace=True)\n",
    "train_df.drop(columns=['rating'], inplace=True)\n",
    "test_df.drop(columns=['rating'], inplace=True)\n",
    "vali_df.drop(columns=['rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matrix of train, vali and test set\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "train = np.zeros((len(user_list), len(item_list)))\n",
    "test = np.zeros((len(user_list), len(item_list)))\n",
    "vali = np.zeros((len(user_list), len(item_list)))\n",
    "for r in range(len(train_df)):\n",
    "    train[user_id_dict[train_df.at[r, 'user_id']], item_id_dict[train_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(test_df)):\n",
    "    test[user_id_dict[test_df.at[r, 'user_id']], item_id_dict[test_df.at[r, 'item_id']]] = 1.0\n",
    "for r in range(len(vali_df)):\n",
    "    vali[user_id_dict[vali_df.at[r, 'user_id']], item_id_dict[vali_df.at[r, 'item_id']]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user int id-> str id list, and the same for item \n",
    "item_list = item_id_dict.keys()\n",
    "item_idd_list = list()\n",
    "for i in range(len(item_list)):\n",
    "    item_idd_list.append('')\n",
    "for item in item_id_dict:\n",
    "    item_idd_list[item_id_dict[item]] = item\n",
    "\n",
    "user_list = user_id_dict.keys()\n",
    "user_idd_list = list()\n",
    "for i in range(len(user_list)):\n",
    "    user_idd_list.append('')\n",
    "for user in user_id_dict:\n",
    "    user_idd_list[user_id_dict[user]] = user\n",
    "    \n",
    "# get the item int id->genres list\n",
    "item_idd_genre_list = list()\n",
    "for i in range(len(item_idd_list)):\n",
    "    item_idd_genre_list.append(item_genre_dict[item_idd_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('user_freq', axis=1, inplace=True)\n",
    "train_df.drop('item_freq', axis=1, inplace=True)\n",
    "vali_df.drop('user_freq', axis=1, inplace=True)\n",
    "vali_df.drop('item_freq', axis=1, inplace=True)\n",
    "test_df.drop('user_freq', axis=1, inplace=True)\n",
    "test_df.drop('item_freq', axis=1, inplace=True)\n",
    "rdf.drop('user_freq', axis=1, inplace=True)\n",
    "rdf.drop('item_freq', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df for rdf, train, vali, test with int id for user and item\n",
    "import copy\n",
    "rating_df = copy.copy(rdf)\n",
    "for i in range(len(rdf)):\n",
    "    rating_df.at[i, 'user_id'] = user_id_dict[rating_df.at[i, 'user_id']]\n",
    "    rating_df.at[i, 'item_id'] = item_id_dict[rating_df.at[i, 'item_id']]\n",
    "\n",
    "training_df = copy.copy(train_df)\n",
    "for i in range(len(training_df)):\n",
    "    training_df.at[i, 'user_id'] = user_id_dict[training_df.at[i, 'user_id']]\n",
    "    training_df.at[i, 'item_id'] = item_id_dict[training_df.at[i, 'item_id']]\n",
    "\n",
    "valiing_df = copy.copy(vali_df)\n",
    "for i in range(len(valiing_df)):\n",
    "    valiing_df.at[i, 'user_id'] = user_id_dict[valiing_df.at[i, 'user_id']]\n",
    "    valiing_df.at[i, 'item_id'] = item_id_dict[valiing_df.at[i, 'item_id']]\n",
    "\n",
    "testing_df = copy.copy(test_df)\n",
    "for i in range(len(testing_df)):\n",
    "    testing_df.at[i, 'user_id'] = user_id_dict[testing_df.at[i, 'user_id']]\n",
    "    testing_df.at[i, 'item_id'] = item_id_dict[testing_df.at[i, 'item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the rating list for each key genre, get the genre->ratings dict\n",
    "rdf.reset_index(drop=True, inplace=True)\n",
    "key_genre_rating = dict()\n",
    "for k in key_genre:\n",
    "    key_genre_rating[k] = 0.0\n",
    "for r in range(len(rdf)):\n",
    "    item = rdf.at[r, 'item_id']\n",
    "    gl = item_genre_dict[item]\n",
    "    for k in key_genre:\n",
    "        if k in gl:\n",
    "            key_genre_rating[k] += 1.0\n",
    "\n",
    "# get the item int id->genres list\n",
    "genre_item_vector = dict()\n",
    "for k in key_genre:\n",
    "    genre_item_vector[k] = np.zeros((1, len(item_list)))\n",
    "for i in range(len(item_idd_genre_list)):\n",
    "    genre_list = item_idd_genre_list[i]\n",
    "    for g in genre_list:\n",
    "        if g in key_genre:\n",
    "            genre_item_vector[g][0, i] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"item_genre_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_genre_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"genre_item_vector.pkl\", \"wb\") as f:\n",
    "    pickle.dump(genre_item_vector, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_id_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_id_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rdf.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rdf, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"rating_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rating_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"training_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(training_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"valiing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(valiing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"testing_df.pkl\", \"wb\") as f:\n",
    "    pickle.dump(testing_df, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_genre_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_genre_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"item_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"user_idd_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_idd_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"key_genre_rating.pkl\", \"wb\") as f:\n",
    "    pickle.dump(key_genre_rating, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(\"train.mat\", \"wb\") as f:\n",
    "    np.save(f, train)\n",
    "with open(\"test.mat\", \"wb\") as f:\n",
    "    np.save(f, test)\n",
    "with open(\"vali.mat\", \"wb\") as f:\n",
    "    np.save(f, vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Toy', 1307), ('Grocery', 1180)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number for each genre and sort\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "item_list = rdf['item_id'].unique()\n",
    "item_genre_dict = pickle.load(open('./item_genre_dict.pkl'))\n",
    "key_genre = pickle.load(open('./key_genre.pkl'))\n",
    "\n",
    "genre_count = dict()\n",
    "for i in item_list:\n",
    "    gl = item_genre_dict[i]\n",
    "    for g in gl:\n",
    "        if g in key_genre:\n",
    "            if not g in genre_count:\n",
    "                genre_count[g] = 1\n",
    "            else:\n",
    "                genre_count[g] += 1\n",
    "\n",
    "# with open(\"genre_count.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(genre_count, f, pickle.HIGHEST_PROTOCOL)\n",
    "                \n",
    "genre_count_sorted = sorted(genre_count.items(), key=itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy as copy\n",
    "train = np.load('./train.mat')\n",
    "item_idd_genre_list = pickle.load(open('./item_idd_genre_list.pkl'))\n",
    "item_idd_genre_list = np.array(item_idd_genre_list)\n",
    "\n",
    "\n",
    "mask = 1.0 * (train > 0)\n",
    "user_genre_count = list()\n",
    "for u in range(train.shape[0]):\n",
    "    temp_genre_count = copy.copy(genre_count)\n",
    "    mask_u = mask[u, :]\n",
    "    gll = item_idd_genre_list[mask_u == 1.0]\n",
    "    for gl in gll:\n",
    "        for g in gl:\n",
    "            if g in key_genre:\n",
    "                temp_genre_count[g] -= 1\n",
    "    user_genre_count.append(temp_genre_count)\n",
    "# with open(\"user_genre_count.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(user_genre_count, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_genre_rating = pickle.load(open('./key_genre_rating.pkl'))\n",
    "genre_avg_like = dict()\n",
    "for k in key_genre:\n",
    "    genre_avg_like[k] = key_genre_rating[k] * 1.0 / genre_count[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Grocery', 46.34661016949153), ('Toy', 23.63045141545524)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_avg_like_sorted = sorted(genre_avg_like.items(), key=itemgetter(1), reverse=True)\n",
    "genre_avg_like_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
